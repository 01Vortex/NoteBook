# 读写分离完全指南

> 基于 Java 8 + Spring Boot 2.7.18 + MySQL 8.0 的读写分离实践

---

## 目录

1. [读写分离概述](#1-读写分离概述)
2. [MySQL 主从复制](#2-mysql-主从复制)
3. [读写分离实现方案](#3-读写分离实现方案)
4. [Spring Boot 手动实现](#4-spring-boot-手动实现)
5. [ShardingSphere-JDBC 实现](#5-shardingsphere-jdbc-实现)
6. [MyCat 中间件实现](#6-mycat-中间件实现)
7. [数据一致性问题](#7-数据一致性问题)
8. [常见错误与排查](#8-常见错误与排查)
9. [最佳实践](#9-最佳实践)

---

## 1. 读写分离概述

### 1.1 什么是读写分离？

读写分离是一种数据库架构设计模式，将数据库的**读操作**和**写操作**分离到不同的数据库实例上执行。

**通俗理解**：就像一个公司里，老板（主库）负责做决策（写），秘书们（从库）负责传达信息（读）。老板做的决定会同步给所有秘书，这样来咨询的人可以找任意一个秘书，不用都去找老板。

```
                        ┌─────────────────────────────────────────────┐
                        │              应用程序                        │
                        └─────────────────────────────────────────────┘
                                          │
                                          ▼
                        ┌─────────────────────────────────────────────┐
                        │           读写分离中间层                      │
                        │    (代码实现 / ShardingSphere / MyCat)       │
                        └─────────────────────────────────────────────┘
                                    │           │
                          写操作    │           │  读操作
                        (INSERT/    │           │  (SELECT)
                         UPDATE/    │           │
                         DELETE)    │           │
                                    ▼           ▼
                        ┌─────────────┐    ┌─────────────┐
                        │   主库      │    │   从库      │
                        │  (Master)   │───▶│  (Slave)    │
                        │   可读写    │同步 │   只读      │
                        └─────────────┘    └─────────────┘
                                                │
                                                ▼
                                          ┌─────────────┐
                                          │   从库 2    │
                                          │  (Slave)    │
                                          └─────────────┘
```

### 1.2 为什么需要读写分离？

#### 业务场景分析

```
典型的互联网应用读写比例：

┌─────────────────────────────────────────────────────────────┐
│  读操作 (SELECT)                                             │
│  ████████████████████████████████████████████████  80-90%   │
├─────────────────────────────────────────────────────────────┤
│  写操作 (INSERT/UPDATE/DELETE)                               │
│  ██████████  10-20%                                         │
└─────────────────────────────────────────────────────────────┘

结论：大部分场景是"读多写少"，读操作是性能瓶颈
```

#### 读写分离的优势

| 优势 | 说明 |
|------|------|
| 提升性能 | 读操作分散到多个从库，减轻主库压力 |
| 提高可用性 | 主库故障时，从库可以提升为主库 |
| 数据备份 | 从库天然就是主库的备份 |
| 扩展性好 | 读压力大时，增加从库即可 |

#### 适用场景

```java
// ✅ 适合读写分离的场景
// 1. 读多写少的业务（电商商品展示、新闻资讯、博客等）
// 2. 对数据实时性要求不高的读操作
// 3. 报表统计类查询（可以在从库执行，不影响主库）

// ❌ 不适合读写分离的场景
// 1. 写操作频繁的业务
// 2. 对数据一致性要求极高的场景（如金融交易）
// 3. 写完立即读的业务逻辑
```


---

## 2. MySQL 主从复制

### 2.1 主从复制原理

读写分离的基础是**主从复制**，理解复制原理对于排查问题至关重要。

```
┌─────────────────────────────────────────────────────────────────────┐
│                      MySQL 主从复制原理                              │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│   主库 (Master)                        从库 (Slave)                  │
│   ┌─────────────┐                     ┌─────────────┐               │
│   │  客户端写入  │                     │             │               │
│   └──────┬──────┘                     │             │               │
│          │                            │             │               │
│          ▼                            │             │               │
│   ┌─────────────┐                     │             │               │
│   │ 写入数据库   │                     │             │               │
│   └──────┬──────┘                     │             │               │
│          │                            │             │               │
│          ▼                            │             │               │
│   ┌─────────────┐    ① 读取          ┌─────────────┐               │
│   │ Binary Log  │◄──────────────────│  I/O Thread │               │
│   │  (binlog)   │                    └──────┬──────┘               │
│   └─────────────┘                           │                       │
│                                             │ ② 写入                │
│                                             ▼                       │
│                                      ┌─────────────┐               │
│                                      │ Relay Log   │               │
│                                      │  (中继日志)  │               │
│                                      └──────┬──────┘               │
│                                             │                       │
│                                             │ ③ 读取并执行          │
│                                             ▼                       │
│                                      ┌─────────────┐               │
│                                      │ SQL Thread  │               │
│                                      └──────┬──────┘               │
│                                             │                       │
│                                             │ ④ 写入从库            │
│                                             ▼                       │
│                                      ┌─────────────┐               │
│                                      │  从库数据    │               │
│                                      └─────────────┘               │
└─────────────────────────────────────────────────────────────────────┘

复制过程：
1. 主库执行写操作，记录到 Binary Log
2. 从库 I/O 线程读取主库的 Binary Log，写入本地 Relay Log
3. 从库 SQL 线程读取 Relay Log，执行 SQL 语句
4. 从库数据与主库保持一致
```

### 2.2 复制模式

#### 2.2.1 异步复制（默认）

```
主库写入 ──▶ 返回客户端 ──▶ 异步同步到从库

特点：
- 性能最好
- 主库不等待从库确认
- 可能丢失数据（主库宕机时）
```

#### 2.2.2 半同步复制

```
主库写入 ──▶ 等待至少一个从库确认 ──▶ 返回客户端

特点：
- 性能略低
- 至少一个从库收到数据才返回
- 数据安全性更高
```

#### 2.2.3 全同步复制（组复制）

```
主库写入 ──▶ 等待所有从库确认 ──▶ 返回客户端

特点：
- 性能最低
- 数据一致性最强
- 适合对一致性要求极高的场景
```

### 2.3 搭建 MySQL 主从复制

#### 2.3.1 环境准备

```bash
# 假设有两台服务器
# 主库: 192.168.1.100:3306
# 从库: 192.168.1.101:3306

# 使用 Docker 快速搭建测试环境
# docker-compose.yml
```

```yaml
version: '3.8'
services:
  mysql-master:
    image: mysql:8.0
    container_name: mysql-master
    environment:
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: testdb
    ports:
      - "3306:3306"
    volumes:
      - ./master/conf:/etc/mysql/conf.d
      - ./master/data:/var/lib/mysql
    command: --server-id=1 --log-bin=mysql-bin --binlog-format=ROW

  mysql-slave:
    image: mysql:8.0
    container_name: mysql-slave
    environment:
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: testdb
    ports:
      - "3307:3306"
    volumes:
      - ./slave/conf:/etc/mysql/conf.d
      - ./slave/data:/var/lib/mysql
    command: --server-id=2 --log-bin=mysql-bin --binlog-format=ROW --read-only=1
    depends_on:
      - mysql-master
```

#### 2.3.2 主库配置

```ini
# master/conf/my.cnf
[mysqld]
# 服务器唯一ID，主库和从库不能相同
server-id=1

# 开启二进制日志
log-bin=mysql-bin

# 二进制日志格式：ROW 模式最安全
binlog-format=ROW

# 需要同步的数据库（可选，不配置则同步所有）
# binlog-do-db=testdb

# 不需要同步的数据库
binlog-ignore-db=mysql
binlog-ignore-db=information_schema
binlog-ignore-db=performance_schema
binlog-ignore-db=sys

# 二进制日志过期时间（天）
expire_logs_days=7

# 单个二进制日志文件最大大小
max_binlog_size=500M

# GTID 模式（推荐开启）
gtid_mode=ON
enforce_gtid_consistency=ON
```

#### 2.3.3 从库配置

```ini
# slave/conf/my.cnf
[mysqld]
# 服务器唯一ID
server-id=2

# 开启二进制日志（从库也建议开启，方便级联复制）
log-bin=mysql-bin
binlog-format=ROW

# 中继日志
relay-log=relay-bin

# 只读模式（从库设置为只读）
read-only=1

# super 用户也只读（更严格）
# super-read-only=1

# GTID 模式
gtid_mode=ON
enforce_gtid_consistency=ON

# 从库并行复制（提高复制效率）
slave_parallel_type=LOGICAL_CLOCK
slave_parallel_workers=4
```

#### 2.3.4 配置主从复制

```sql
-- ========== 在主库执行 ==========

-- 1. 创建复制用户
CREATE USER 'repl'@'%' IDENTIFIED BY 'repl123';
GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
FLUSH PRIVILEGES;

-- 2. 查看主库状态（记录 File 和 Position）
SHOW MASTER STATUS;
-- +------------------+----------+--------------+------------------+
-- | File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |
-- +------------------+----------+--------------+------------------+
-- | mysql-bin.000003 |      856 |              | mysql,...        |
-- +------------------+----------+--------------+------------------+

-- ========== 在从库执行 ==========

-- 3. 配置主库连接信息
-- 方式一：基于 binlog 位置（传统方式）
CHANGE MASTER TO
    MASTER_HOST='192.168.1.100',
    MASTER_PORT=3306,
    MASTER_USER='repl',
    MASTER_PASSWORD='repl123',
    MASTER_LOG_FILE='mysql-bin.000003',
    MASTER_LOG_POS=856;

-- 方式二：基于 GTID（推荐）
CHANGE MASTER TO
    MASTER_HOST='192.168.1.100',
    MASTER_PORT=3306,
    MASTER_USER='repl',
    MASTER_PASSWORD='repl123',
    MASTER_AUTO_POSITION=1;

-- 4. 启动从库复制
START SLAVE;

-- 5. 查看从库状态
SHOW SLAVE STATUS\G
-- 关键字段：
-- Slave_IO_Running: Yes   (I/O 线程正常)
-- Slave_SQL_Running: Yes  (SQL 线程正常)
-- Seconds_Behind_Master: 0 (延迟秒数)
```

#### 2.3.5 验证主从复制

```sql
-- 在主库创建测试数据
CREATE DATABASE IF NOT EXISTS testdb;
USE testdb;

CREATE TABLE users (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(50) NOT NULL,
    email VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INSERT INTO users (username, email) VALUES ('张三', 'zhangsan@example.com');
INSERT INTO users (username, email) VALUES ('李四', 'lisi@example.com');

-- 在从库查询验证
SELECT * FROM testdb.users;
-- 应该能看到主库插入的数据
```


---

## 3. 读写分离实现方案

### 3.1 方案对比

```
┌─────────────────────────────────────────────────────────────────────┐
│                      读写分离实现方案对比                            │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  方案一：代码层实现                                                   │
│  ┌─────────────────────────────────────────────────────────────┐    │
│  │  应用程序                                                    │    │
│  │  ┌─────────────────────────────────────────────────────┐    │    │
│  │  │  AbstractRoutingDataSource + AOP                    │    │    │
│  │  │  自己实现数据源路由逻辑                               │    │    │
│  │  └─────────────────────────────────────────────────────┘    │    │
│  └─────────────────────────────────────────────────────────────┘    │
│  优点：灵活可控，无额外依赖                                          │
│  缺点：需要自己实现，维护成本高                                       │
│                                                                      │
│  方案二：ShardingSphere-JDBC                                         │
│  ┌─────────────────────────────────────────────────────────────┐    │
│  │  应用程序                                                    │    │
│  │  ┌─────────────────────────────────────────────────────┐    │    │
│  │  │  ShardingSphere-JDBC (JAR 包)                       │    │    │
│  │  │  增强版 JDBC 驱动，透明化读写分离                     │    │    │
│  │  └─────────────────────────────────────────────────────┘    │    │
│  └─────────────────────────────────────────────────────────────┘    │
│  优点：配置简单，功能强大，社区活跃                                   │
│  缺点：引入额外依赖，有一定学习成本                                   │
│                                                                      │
│  方案三：数据库中间件 (MyCat/ProxySQL)                               │
│  ┌─────────────────────────────────────────────────────────────┐    │
│  │  应用程序                                                    │    │
│  │  ┌─────────────────────────────────────────────────────┐    │    │
│  │  │  普通 JDBC 连接                                      │    │    │
│  │  └─────────────────────────────────────────────────────┘    │    │
│  │                          │                                   │    │
│  │                          ▼                                   │    │
│  │  ┌─────────────────────────────────────────────────────┐    │    │
│  │  │  MyCat / ProxySQL (独立服务)                        │    │    │
│  │  │  数据库代理，对应用透明                              │    │    │
│  │  └─────────────────────────────────────────────────────┘    │    │
│  └─────────────────────────────────────────────────────────────┘    │
│  优点：对应用完全透明，支持多语言                                     │
│  缺点：增加运维复杂度，有单点风险                                     │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

### 3.2 方案选择建议

| 场景 | 推荐方案 | 理由 |
|------|---------|------|
| 小型项目 | 代码层实现 | 简单够用，无额外依赖 |
| 中型项目 | ShardingSphere-JDBC | 功能完善，配置简单 |
| 大型项目/多语言 | MyCat/ProxySQL | 统一管理，对应用透明 |
| 需要分库分表 | ShardingSphere | 读写分离+分库分表一体化 |

---

## 4. Spring Boot 手动实现

### 4.1 项目结构

```
src/main/java/com/example/readwrite/
├── config/
│   ├── DataSourceConfig.java          # 数据源配置
│   ├── DynamicDataSource.java         # 动态数据源
│   └── DataSourceContextHolder.java   # 数据源上下文
├── annotation/
│   └── ReadOnly.java                  # 只读注解
├── aspect/
│   └── DataSourceAspect.java          # 数据源切面
├── enums/
│   └── DataSourceType.java            # 数据源类型枚举
├── entity/
│   └── User.java
├── mapper/
│   └── UserMapper.java
├── service/
│   ├── UserService.java
│   └── impl/UserServiceImpl.java
└── ReadWriteApplication.java
```

### 4.2 Maven 依赖

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.7.18</version>
    </parent>
    
    <groupId>com.example</groupId>
    <artifactId>read-write-demo</artifactId>
    <version>1.0.0</version>
    
    <properties>
        <java.version>1.8</java.version>
    </properties>
    
    <dependencies>
        <!-- Spring Boot Web -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        
        <!-- Spring Boot AOP -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-aop</artifactId>
        </dependency>
        
        <!-- MyBatis -->
        <dependency>
            <groupId>org.mybatis.spring.boot</groupId>
            <artifactId>mybatis-spring-boot-starter</artifactId>
            <version>2.3.1</version>
        </dependency>
        
        <!-- MySQL 驱动 -->
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>8.0.33</version>
        </dependency>
        
        <!-- HikariCP 连接池 (Spring Boot 默认) -->
        <dependency>
            <groupId>com.zaxxer</groupId>
            <artifactId>HikariCP</artifactId>
        </dependency>
        
        <!-- Lombok -->
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
    </dependencies>
</project>
```

### 4.3 配置文件

```yaml
# application.yml
spring:
  datasource:
    # 主库配置
    master:
      driver-class-name: com.mysql.cj.jdbc.Driver
      jdbc-url: jdbc:mysql://192.168.1.100:3306/testdb?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
      username: root
      password: root123
      # HikariCP 连接池配置
      hikari:
        pool-name: MasterHikariPool
        minimum-idle: 5
        maximum-pool-size: 20
        idle-timeout: 30000
        max-lifetime: 1800000
        connection-timeout: 30000
    
    # 从库配置
    slave:
      driver-class-name: com.mysql.cj.jdbc.Driver
      jdbc-url: jdbc:mysql://192.168.1.101:3306/testdb?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
      username: root
      password: root123
      hikari:
        pool-name: SlaveHikariPool
        minimum-idle: 5
        maximum-pool-size: 20
        idle-timeout: 30000
        max-lifetime: 1800000
        connection-timeout: 30000

# MyBatis 配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.example.readwrite.entity
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

# 日志配置
logging:
  level:
    com.example.readwrite: debug
```

### 4.4 核心代码实现

#### 4.4.1 数据源类型枚举

```java
package com.example.readwrite.enums;

/**
 * 数据源类型枚举
 */
public enum DataSourceType {
    
    /**
     * 主库 - 用于写操作
     */
    MASTER,
    
    /**
     * 从库 - 用于读操作
     */
    SLAVE
}
```

#### 4.4.2 数据源上下文持有者

```java
package com.example.readwrite.config;

import com.example.readwrite.enums.DataSourceType;
import lombok.extern.slf4j.Slf4j;

/**
 * 数据源上下文持有者
 * 使用 ThreadLocal 保存当前线程使用的数据源类型
 * 
 * 原理：每个线程有自己独立的数据源类型，互不干扰
 */
@Slf4j
public class DataSourceContextHolder {
    
    /**
     * 使用 ThreadLocal 保存数据源类型
     * 为什么用 ThreadLocal？
     * - 每个请求是一个独立的线程
     * - 不同请求可能需要不同的数据源
     * - ThreadLocal 保证线程隔离
     */
    private static final ThreadLocal<DataSourceType> CONTEXT_HOLDER = new ThreadLocal<>();
    
    /**
     * 设置数据源类型
     */
    public static void setDataSourceType(DataSourceType dataSourceType) {
        if (dataSourceType == null) {
            throw new NullPointerException("数据源类型不能为空");
        }
        log.debug("切换数据源到: {}", dataSourceType);
        CONTEXT_HOLDER.set(dataSourceType);
    }
    
    /**
     * 获取当前数据源类型
     * 默认返回主库
     */
    public static DataSourceType getDataSourceType() {
        DataSourceType dataSourceType = CONTEXT_HOLDER.get();
        // 默认使用主库，保证数据安全
        return dataSourceType == null ? DataSourceType.MASTER : dataSourceType;
    }
    
    /**
     * 清除数据源类型
     * 重要：必须在请求结束后清除，防止内存泄漏和数据源污染
     */
    public static void clearDataSourceType() {
        log.debug("清除数据源上下文");
        CONTEXT_HOLDER.remove();
    }
    
    /**
     * 设置为主库
     */
    public static void useMaster() {
        setDataSourceType(DataSourceType.MASTER);
    }
    
    /**
     * 设置为从库
     */
    public static void useSlave() {
        setDataSourceType(DataSourceType.SLAVE);
    }
}
```

#### 4.4.3 动态数据源

```java
package com.example.readwrite.config;

import com.example.readwrite.enums.DataSourceType;
import lombok.extern.slf4j.Slf4j;
import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;

/**
 * 动态数据源
 * 继承 Spring 提供的 AbstractRoutingDataSource
 * 
 * 原理：
 * AbstractRoutingDataSource 内部维护了一个 Map<Object, DataSource>
 * 通过 determineCurrentLookupKey() 方法返回的 key 来决定使用哪个数据源
 */
@Slf4j
public class DynamicDataSource extends AbstractRoutingDataSource {
    
    /**
     * 决定当前使用哪个数据源
     * 这个方法会在每次获取数据库连接时被调用
     * 
     * @return 数据源的 key（对应 targetDataSources 中的 key）
     */
    @Override
    protected Object determineCurrentLookupKey() {
        DataSourceType dataSourceType = DataSourceContextHolder.getDataSourceType();
        log.debug("当前数据源: {}", dataSourceType);
        return dataSourceType;
    }
}
```

#### 4.4.4 数据源配置类

```java
package com.example.readwrite.config;

import com.example.readwrite.enums.DataSourceType;
import com.zaxxer.hikari.HikariDataSource;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.boot.jdbc.DataSourceBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;

import javax.sql.DataSource;
import java.util.HashMap;
import java.util.Map;

/**
 * 数据源配置类
 */
@Slf4j
@Configuration
public class DataSourceConfig {
    
    /**
     * 主库数据源
     */
    @Bean("masterDataSource")
    @ConfigurationProperties(prefix = "spring.datasource.master")
    public DataSource masterDataSource() {
        log.info("初始化主库数据源");
        return DataSourceBuilder.create()
                .type(HikariDataSource.class)
                .build();
    }
    
    /**
     * 从库数据源
     */
    @Bean("slaveDataSource")
    @ConfigurationProperties(prefix = "spring.datasource.slave")
    public DataSource slaveDataSource() {
        log.info("初始化从库数据源");
        return DataSourceBuilder.create()
                .type(HikariDataSource.class)
                .build();
    }
    
    /**
     * 动态数据源
     * @Primary 注解表示这是主要的数据源，Spring 会优先使用
     */
    @Bean("dynamicDataSource")
    @Primary
    public DataSource dynamicDataSource() {
        DynamicDataSource dynamicDataSource = new DynamicDataSource();
        
        // 设置目标数据源
        Map<Object, Object> targetDataSources = new HashMap<>(2);
        targetDataSources.put(DataSourceType.MASTER, masterDataSource());
        targetDataSources.put(DataSourceType.SLAVE, slaveDataSource());
        dynamicDataSource.setTargetDataSources(targetDataSources);
        
        // 设置默认数据源为主库
        dynamicDataSource.setDefaultTargetDataSource(masterDataSource());
        
        log.info("动态数据源初始化完成，主库和从库已配置");
        return dynamicDataSource;
    }
}
```


#### 4.4.5 只读注解

```java
package com.example.readwrite.annotation;

import java.lang.annotation.*;

/**
 * 只读注解
 * 标注在方法或类上，表示该方法/类中的所有数据库操作使用从库
 * 
 * 使用示例：
 * @ReadOnly
 * public User getUserById(Long id) { ... }
 */
@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface ReadOnly {
    
    /**
     * 是否强制使用从库
     * true: 即使在事务中也使用从库（慎用）
     * false: 如果在事务中，仍使用主库
     */
    boolean force() default false;
}
```

#### 4.4.6 数据源切面

```java
package com.example.readwrite.aspect;

import com.example.readwrite.annotation.ReadOnly;
import com.example.readwrite.config.DataSourceContextHolder;
import com.example.readwrite.enums.DataSourceType;
import lombok.extern.slf4j.Slf4j;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.annotation.Pointcut;
import org.aspectj.lang.reflect.MethodSignature;
import org.springframework.core.annotation.Order;
import org.springframework.stereotype.Component;
import org.springframework.transaction.support.TransactionSynchronizationManager;

import java.lang.reflect.Method;

/**
 * 数据源切换切面
 * 
 * @Order(-1) 保证在事务切面之前执行
 * 因为事务开启时会获取数据库连接，必须在此之前确定数据源
 */
@Slf4j
@Aspect
@Component
@Order(-1)
public class DataSourceAspect {
    
    /**
     * 切点：所有 Service 层的方法
     */
    @Pointcut("execution(* com.example.readwrite.service..*.*(..))")
    public void servicePointcut() {}
    
    /**
     * 切点：标注了 @ReadOnly 注解的方法
     */
    @Pointcut("@annotation(com.example.readwrite.annotation.ReadOnly)")
    public void readOnlyPointcut() {}
    
    /**
     * 环绕通知：根据注解或方法名自动切换数据源
     */
    @Around("servicePointcut()")
    public Object around(ProceedingJoinPoint point) throws Throwable {
        DataSourceType dataSourceType = determineDataSource(point);
        
        try {
            DataSourceContextHolder.setDataSourceType(dataSourceType);
            return point.proceed();
        } finally {
            // 重要：方法执行完毕后清除数据源，防止污染其他请求
            DataSourceContextHolder.clearDataSourceType();
        }
    }
    
    /**
     * 决定使用哪个数据源
     */
    private DataSourceType determineDataSource(ProceedingJoinPoint point) {
        MethodSignature signature = (MethodSignature) point.getSignature();
        Method method = signature.getMethod();
        Class<?> targetClass = point.getTarget().getClass();
        
        // 1. 检查方法上是否有 @ReadOnly 注解
        ReadOnly methodAnnotation = method.getAnnotation(ReadOnly.class);
        if (methodAnnotation != null) {
            return handleReadOnlyAnnotation(methodAnnotation);
        }
        
        // 2. 检查类上是否有 @ReadOnly 注解
        ReadOnly classAnnotation = targetClass.getAnnotation(ReadOnly.class);
        if (classAnnotation != null) {
            return handleReadOnlyAnnotation(classAnnotation);
        }
        
        // 3. 根据方法名前缀判断（约定优于配置）
        String methodName = method.getName();
        if (isReadMethod(methodName)) {
            // 如果当前在事务中，使用主库保证数据一致性
            if (TransactionSynchronizationManager.isActualTransactionActive()) {
                log.debug("方法 {} 在事务中，使用主库", methodName);
                return DataSourceType.MASTER;
            }
            return DataSourceType.SLAVE;
        }
        
        // 4. 默认使用主库
        return DataSourceType.MASTER;
    }
    
    /**
     * 处理 @ReadOnly 注解
     */
    private DataSourceType handleReadOnlyAnnotation(ReadOnly annotation) {
        // 如果强制使用从库，或者不在事务中，使用从库
        if (annotation.force() || !TransactionSynchronizationManager.isActualTransactionActive()) {
            return DataSourceType.SLAVE;
        }
        // 在事务中且非强制，使用主库
        log.debug("在事务中，@ReadOnly 注解不生效，使用主库");
        return DataSourceType.MASTER;
    }
    
    /**
     * 判断是否是读方法
     * 根据方法名前缀判断
     */
    private boolean isReadMethod(String methodName) {
        // 读操作的方法名前缀
        String[] readPrefixes = {
            "get", "find", "query", "select", "list", 
            "count", "exist", "search", "fetch", "load"
        };
        
        for (String prefix : readPrefixes) {
            if (methodName.startsWith(prefix)) {
                return true;
            }
        }
        return false;
    }
}
```

### 4.5 业务代码示例

#### 4.5.1 实体类

```java
package com.example.readwrite.entity;

import lombok.Data;
import java.time.LocalDateTime;

@Data
public class User {
    private Long id;
    private String username;
    private String email;
    private LocalDateTime createdAt;
    private LocalDateTime updatedAt;
}
```

#### 4.5.2 Mapper 接口

```java
package com.example.readwrite.mapper;

import com.example.readwrite.entity.User;
import org.apache.ibatis.annotations.*;

import java.util.List;

@Mapper
public interface UserMapper {
    
    @Select("SELECT * FROM users WHERE id = #{id}")
    User selectById(Long id);
    
    @Select("SELECT * FROM users")
    List<User> selectAll();
    
    @Insert("INSERT INTO users (username, email) VALUES (#{username}, #{email})")
    @Options(useGeneratedKeys = true, keyProperty = "id")
    int insert(User user);
    
    @Update("UPDATE users SET username = #{username}, email = #{email}, updated_at = NOW() WHERE id = #{id}")
    int update(User user);
    
    @Delete("DELETE FROM users WHERE id = #{id}")
    int deleteById(Long id);
}
```

#### 4.5.3 Service 接口

```java
package com.example.readwrite.service;

import com.example.readwrite.entity.User;
import java.util.List;

public interface UserService {
    
    /**
     * 根据 ID 查询用户（走从库）
     */
    User getUserById(Long id);
    
    /**
     * 查询所有用户（走从库）
     */
    List<User> getAllUsers();
    
    /**
     * 创建用户（走主库）
     */
    User createUser(User user);
    
    /**
     * 更新用户（走主库）
     */
    User updateUser(User user);
    
    /**
     * 删除用户（走主库）
     */
    void deleteUser(Long id);
    
    /**
     * 创建用户并立即查询（演示写后读问题）
     */
    User createAndGet(User user);
}
```

#### 4.5.4 Service 实现

```java
package com.example.readwrite.service.impl;

import com.example.readwrite.annotation.ReadOnly;
import com.example.readwrite.config.DataSourceContextHolder;
import com.example.readwrite.entity.User;
import com.example.readwrite.mapper.UserMapper;
import com.example.readwrite.service.UserService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.List;

@Slf4j
@Service
@RequiredArgsConstructor
public class UserServiceImpl implements UserService {
    
    private final UserMapper userMapper;
    
    /**
     * 查询用户 - 自动走从库
     * 方法名以 get 开头，切面会自动路由到从库
     */
    @Override
    @ReadOnly  // 也可以显式标注
    public User getUserById(Long id) {
        log.info("查询用户，ID: {}", id);
        return userMapper.selectById(id);
    }
    
    /**
     * 查询所有用户 - 自动走从库
     */
    @Override
    @ReadOnly
    public List<User> getAllUsers() {
        log.info("查询所有用户");
        return userMapper.selectAll();
    }
    
    /**
     * 创建用户 - 走主库
     * 方法名以 create 开头，切面会路由到主库
     */
    @Override
    @Transactional(rollbackFor = Exception.class)
    public User createUser(User user) {
        log.info("创建用户: {}", user.getUsername());
        userMapper.insert(user);
        return user;
    }
    
    /**
     * 更新用户 - 走主库
     */
    @Override
    @Transactional(rollbackFor = Exception.class)
    public User updateUser(User user) {
        log.info("更新用户，ID: {}", user.getId());
        userMapper.update(user);
        return userMapper.selectById(user.getId());
    }
    
    /**
     * 删除用户 - 走主库
     */
    @Override
    @Transactional(rollbackFor = Exception.class)
    public void deleteUser(Long id) {
        log.info("删除用户，ID: {}", id);
        userMapper.deleteById(id);
    }
    
    /**
     * 创建并查询 - 演示写后读问题
     * 
     * 问题：写入主库后立即从从库读取，可能读不到数据（主从延迟）
     * 解决：在同一个事务中，强制使用主库读取
     */
    @Override
    @Transactional(rollbackFor = Exception.class)
    public User createAndGet(User user) {
        log.info("创建并查询用户: {}", user.getUsername());
        
        // 写入主库
        userMapper.insert(user);
        
        // 方案一：在事务中，切面会自动使用主库
        // 因为 @Transactional 开启了事务，切面检测到事务后会使用主库
        
        // 方案二：手动强制使用主库
        // DataSourceContextHolder.useMaster();
        
        // 查询刚插入的数据
        return userMapper.selectById(user.getId());
    }
}
```

#### 4.5.5 Controller

```java
package com.example.readwrite.controller;

import com.example.readwrite.entity.User;
import com.example.readwrite.service.UserService;
import lombok.RequiredArgsConstructor;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@RestController
@RequestMapping("/api/users")
@RequiredArgsConstructor
public class UserController {
    
    private final UserService userService;
    
    @GetMapping("/{id}")
    public User getUser(@PathVariable Long id) {
        return userService.getUserById(id);
    }
    
    @GetMapping
    public List<User> getAllUsers() {
        return userService.getAllUsers();
    }
    
    @PostMapping
    public User createUser(@RequestBody User user) {
        return userService.createUser(user);
    }
    
    @PutMapping("/{id}")
    public User updateUser(@PathVariable Long id, @RequestBody User user) {
        user.setId(id);
        return userService.updateUser(user);
    }
    
    @DeleteMapping("/{id}")
    public void deleteUser(@PathVariable Long id) {
        userService.deleteUser(id);
    }
}
```


### 4.6 多从库负载均衡

当有多个从库时，需要实现负载均衡策略。

```java
package com.example.readwrite.config;

import com.example.readwrite.enums.DataSourceType;
import com.zaxxer.hikari.HikariDataSource;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.boot.jdbc.DataSourceBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;

import javax.sql.DataSource;
import java.util.HashMap;
import java.util.Map;

/**
 * 多从库数据源配置
 */
@Slf4j
@Configuration
public class MultiSlaveDataSourceConfig {
    
    @Bean("masterDataSource")
    @ConfigurationProperties(prefix = "spring.datasource.master")
    public DataSource masterDataSource() {
        return DataSourceBuilder.create().type(HikariDataSource.class).build();
    }
    
    @Bean("slave1DataSource")
    @ConfigurationProperties(prefix = "spring.datasource.slave1")
    public DataSource slave1DataSource() {
        return DataSourceBuilder.create().type(HikariDataSource.class).build();
    }
    
    @Bean("slave2DataSource")
    @ConfigurationProperties(prefix = "spring.datasource.slave2")
    public DataSource slave2DataSource() {
        return DataSourceBuilder.create().type(HikariDataSource.class).build();
    }
    
    @Bean("dynamicDataSource")
    @Primary
    public DataSource dynamicDataSource() {
        // 使用支持负载均衡的动态数据源
        LoadBalanceDynamicDataSource dynamicDataSource = new LoadBalanceDynamicDataSource();
        
        // 设置主库
        dynamicDataSource.setMasterDataSource(masterDataSource());
        
        // 设置从库列表
        dynamicDataSource.addSlaveDataSource("slave1", slave1DataSource());
        dynamicDataSource.addSlaveDataSource("slave2", slave2DataSource());
        
        // 设置负载均衡策略
        dynamicDataSource.setLoadBalanceStrategy(LoadBalanceStrategy.ROUND_ROBIN);
        
        return dynamicDataSource;
    }
}
```

```java
package com.example.readwrite.config;

import com.example.readwrite.enums.DataSourceType;
import lombok.extern.slf4j.Slf4j;
import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;

import javax.sql.DataSource;
import java.util.*;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * 支持负载均衡的动态数据源
 */
@Slf4j
public class LoadBalanceDynamicDataSource extends AbstractRoutingDataSource {
    
    private DataSource masterDataSource;
    private List<DataSource> slaveDataSources = new ArrayList<>();
    private List<String> slaveKeys = new ArrayList<>();
    private LoadBalanceStrategy strategy = LoadBalanceStrategy.ROUND_ROBIN;
    
    // 轮询计数器
    private AtomicInteger counter = new AtomicInteger(0);
    // 随机数生成器
    private Random random = new Random();
    
    public void setMasterDataSource(DataSource masterDataSource) {
        this.masterDataSource = masterDataSource;
    }
    
    public void addSlaveDataSource(String key, DataSource slaveDataSource) {
        this.slaveKeys.add(key);
        this.slaveDataSources.add(slaveDataSource);
    }
    
    public void setLoadBalanceStrategy(LoadBalanceStrategy strategy) {
        this.strategy = strategy;
    }
    
    @Override
    public void afterPropertiesSet() {
        // 构建目标数据源 Map
        Map<Object, Object> targetDataSources = new HashMap<>();
        targetDataSources.put(DataSourceType.MASTER, masterDataSource);
        
        for (int i = 0; i < slaveKeys.size(); i++) {
            targetDataSources.put(slaveKeys.get(i), slaveDataSources.get(i));
        }
        
        setTargetDataSources(targetDataSources);
        setDefaultTargetDataSource(masterDataSource);
        
        super.afterPropertiesSet();
    }
    
    @Override
    protected Object determineCurrentLookupKey() {
        DataSourceType dataSourceType = DataSourceContextHolder.getDataSourceType();
        
        if (dataSourceType == DataSourceType.MASTER || slaveDataSources.isEmpty()) {
            log.debug("使用主库");
            return DataSourceType.MASTER;
        }
        
        // 从库负载均衡
        String slaveKey = selectSlave();
        log.debug("使用从库: {}", slaveKey);
        return slaveKey;
    }
    
    /**
     * 选择从库
     */
    private String selectSlave() {
        if (slaveKeys.isEmpty()) {
            return null;
        }
        
        int index;
        switch (strategy) {
            case ROUND_ROBIN:
                // 轮询
                index = counter.getAndIncrement() % slaveKeys.size();
                break;
            case RANDOM:
                // 随机
                index = random.nextInt(slaveKeys.size());
                break;
            case WEIGHT:
                // 权重（简化实现，实际应根据配置的权重选择）
                index = selectByWeight();
                break;
            default:
                index = 0;
        }
        
        return slaveKeys.get(index);
    }
    
    /**
     * 按权重选择（简化实现）
     */
    private int selectByWeight() {
        // 实际项目中应该根据配置的权重来选择
        // 这里简化为轮询
        return counter.getAndIncrement() % slaveKeys.size();
    }
}

/**
 * 负载均衡策略
 */
enum LoadBalanceStrategy {
    ROUND_ROBIN,  // 轮询
    RANDOM,       // 随机
    WEIGHT        // 权重
}
```

---

## 5. ShardingSphere-JDBC 实现

### 5.1 简介

ShardingSphere-JDBC 是 Apache ShardingSphere 的 JDBC 驱动版本，以 JAR 包形式提供服务，无需额外部署，配置简单，功能强大。

```
┌─────────────────────────────────────────────────────────────────────┐
│                    ShardingSphere-JDBC 架构                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│   应用程序                                                           │
│   ┌─────────────────────────────────────────────────────────────┐   │
│   │  业务代码                                                    │   │
│   └─────────────────────────────────────────────────────────────┘   │
│                              │                                       │
│                              ▼                                       │
│   ┌─────────────────────────────────────────────────────────────┐   │
│   │  ShardingSphere-JDBC                                        │   │
│   │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │   │
│   │  │ SQL 解析    │→ │ SQL 路由    │→ │ SQL 改写/执行/归并  │  │   │
│   │  └─────────────┘  └─────────────┘  └─────────────────────┘  │   │
│   └─────────────────────────────────────────────────────────────┘   │
│                              │                                       │
│              ┌───────────────┼───────────────┐                      │
│              ▼               ▼               ▼                      │
│        ┌──────────┐    ┌──────────┐    ┌──────────┐                │
│        │  主库    │    │  从库1   │    │  从库2   │                │
│        └──────────┘    └──────────┘    └──────────┘                │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

### 5.2 Maven 依赖

```xml
<dependencies>
    <!-- Spring Boot Starter -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    
    <!-- ShardingSphere JDBC -->
    <dependency>
        <groupId>org.apache.shardingsphere</groupId>
        <artifactId>shardingsphere-jdbc-core-spring-boot-starter</artifactId>
        <version>5.3.2</version>
    </dependency>
    
    <!-- MySQL 驱动 -->
    <dependency>
        <groupId>mysql</groupId>
        <artifactId>mysql-connector-java</artifactId>
        <version>8.0.33</version>
    </dependency>
    
    <!-- MyBatis -->
    <dependency>
        <groupId>org.mybatis.spring.boot</groupId>
        <artifactId>mybatis-spring-boot-starter</artifactId>
        <version>2.3.1</version>
    </dependency>
    
    <!-- HikariCP -->
    <dependency>
        <groupId>com.zaxxer</groupId>
        <artifactId>HikariCP</artifactId>
    </dependency>
</dependencies>
```

### 5.3 配置文件

```yaml
# application.yml
spring:
  shardingsphere:
    # 数据源配置
    datasource:
      names: master,slave1,slave2
      
      # 主库
      master:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://192.168.1.100:3306/testdb?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
        username: root
        password: root123
        hikari:
          pool-name: MasterPool
          minimum-idle: 5
          maximum-pool-size: 20
      
      # 从库1
      slave1:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://192.168.1.101:3306/testdb?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
        username: root
        password: root123
        hikari:
          pool-name: Slave1Pool
          minimum-idle: 5
          maximum-pool-size: 20
      
      # 从库2
      slave2:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        jdbc-url: jdbc:mysql://192.168.1.102:3306/testdb?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
        username: root
        password: root123
        hikari:
          pool-name: Slave2Pool
          minimum-idle: 5
          maximum-pool-size: 20
    
    # 读写分离规则
    rules:
      readwrite-splitting:
        data-sources:
          # 读写分离数据源名称
          readwrite_ds:
            # 静态读写分离配置
            static-strategy:
              # 写数据源
              write-data-source-name: master
              # 读数据源列表
              read-data-source-names:
                - slave1
                - slave2
            # 负载均衡算法名称
            load-balancer-name: round_robin
        
        # 负载均衡算法配置
        load-balancers:
          round_robin:
            type: ROUND_ROBIN
          random:
            type: RANDOM
          weight:
            type: WEIGHT
            props:
              slave1: 1
              slave2: 2
    
    # 属性配置
    props:
      # 显示 SQL
      sql-show: true
      # SQL 简单显示
      sql-simple: false

# MyBatis 配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.example.sharding.entity
  configuration:
    map-underscore-to-camel-case: true
```

### 5.4 使用示例

使用 ShardingSphere-JDBC 后，业务代码**无需任何修改**，读写分离完全透明。

```java
package com.example.sharding.service.impl;

import com.example.sharding.entity.User;
import com.example.sharding.mapper.UserMapper;
import com.example.sharding.service.UserService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.List;

@Slf4j
@Service
@RequiredArgsConstructor
public class UserServiceImpl implements UserService {
    
    private final UserMapper userMapper;
    
    /**
     * 查询操作 - ShardingSphere 自动路由到从库
     * 无需任何注解或配置
     */
    @Override
    public User getUserById(Long id) {
        log.info("查询用户，ID: {}", id);
        // ShardingSphere 检测到 SELECT 语句，自动路由到从库
        return userMapper.selectById(id);
    }
    
    @Override
    public List<User> getAllUsers() {
        // 自动路由到从库
        return userMapper.selectAll();
    }
    
    /**
     * 写操作 - ShardingSphere 自动路由到主库
     */
    @Override
    @Transactional(rollbackFor = Exception.class)
    public User createUser(User user) {
        log.info("创建用户: {}", user.getUsername());
        // ShardingSphere 检测到 INSERT 语句，自动路由到主库
        userMapper.insert(user);
        return user;
    }
    
    /**
     * 事务中的读操作 - ShardingSphere 自动路由到主库
     * 保证事务中读写一致性
     */
    @Override
    @Transactional(rollbackFor = Exception.class)
    public User createAndGet(User user) {
        // INSERT 路由到主库
        userMapper.insert(user);
        
        // 在事务中，SELECT 也会路由到主库
        // ShardingSphere 自动处理，无需手动干预
        return userMapper.selectById(user.getId());
    }
}
```

### 5.5 强制路由

某些场景下需要强制指定数据源，ShardingSphere 提供了 Hint 机制。

```java
package com.example.sharding.service.impl;

import org.apache.shardingsphere.infra.hint.HintManager;
import org.springframework.stereotype.Service;

@Service
public class HintDemoService {
    
    /**
     * 强制走主库查询
     * 场景：写入后立即读取，需要保证数据一致性
     */
    public User getFromMaster(Long id) {
        // 使用 HintManager 强制路由到主库
        try (HintManager hintManager = HintManager.getInstance()) {
            // 设置强制走主库
            hintManager.setWriteRouteOnly();
            
            // 这个查询会路由到主库
            return userMapper.selectById(id);
        }
        // try-with-resources 自动清理 HintManager
    }
    
    /**
     * 强制走指定从库
     */
    public User getFromSpecificSlave(Long id) {
        try (HintManager hintManager = HintManager.getInstance()) {
            // 设置强制走读库
            hintManager.setReadwriteSplittingAuto();
            
            return userMapper.selectById(id);
        }
    }
}
```

### 5.6 动态读写分离（主从延迟检测）

ShardingSphere 5.x 支持动态读写分离，可以根据主从延迟自动剔除延迟过高的从库。

```yaml
spring:
  shardingsphere:
    rules:
      readwrite-splitting:
        data-sources:
          readwrite_ds:
            # 动态读写分离配置
            dynamic-strategy:
              # 自动感知数据源
              auto-aware-data-source-name: readwrite_ds
            load-balancer-name: round_robin
```


---

## 6. MyCat 中间件实现

### 6.1 简介

MyCat 是一个开源的数据库中间件，作为独立的代理服务部署，对应用完全透明。

```
┌─────────────────────────────────────────────────────────────────────┐
│                        MyCat 架构                                    │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│   应用程序 1    应用程序 2    应用程序 3                              │
│       │            │            │                                    │
│       └────────────┼────────────┘                                    │
│                    │                                                 │
│                    ▼                                                 │
│   ┌─────────────────────────────────────────────────────────────┐   │
│   │                    MyCat Server                              │   │
│   │                    (独立部署)                                 │   │
│   │  ┌─────────────────────────────────────────────────────┐    │   │
│   │  │  SQL 解析 → 路由计算 → SQL 执行 → 结果合并          │    │   │
│   │  └─────────────────────────────────────────────────────┘    │   │
│   │  对外暴露 MySQL 协议，应用像连接普通 MySQL 一样连接       │   │
│   └─────────────────────────────────────────────────────────────┘   │
│                    │                                                 │
│        ┌──────────┼──────────┐                                      │
│        ▼          ▼          ▼                                      │
│   ┌──────────┐ ┌──────────┐ ┌──────────┐                           │
│   │  主库    │ │  从库1   │ │  从库2   │                           │
│   │ (写)     │ │ (读)     │ │ (读)     │                           │
│   └──────────┘ └──────────┘ └──────────┘                           │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

### 6.2 MyCat 安装配置

```bash
# 1. 下载 MyCat
wget http://dl.mycat.org.cn/1.6.7.6/20210303094759/Mycat-server-1.6.7.6-release-20210303094759-linux.tar.gz

# 2. 解压
tar -zxvf Mycat-server-1.6.7.6-release-20210303094759-linux.tar.gz

# 3. 目录结构
mycat/
├── bin/          # 启动脚本
├── conf/         # 配置文件
│   ├── server.xml      # MyCat 服务配置
│   ├── schema.xml      # 数据库和表配置
│   └── rule.xml        # 分片规则配置
├── lib/          # 依赖 JAR
└── logs/         # 日志文件
```

### 6.3 配置文件

#### 6.3.1 server.xml - 服务配置

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:server SYSTEM "server.dtd">
<mycat:server xmlns:mycat="http://io.mycat/">
    
    <!-- 系统配置 -->
    <system>
        <!-- MyCat 服务端口 -->
        <property name="serverPort">8066</property>
        <!-- 管理端口 -->
        <property name="managerPort">9066</property>
        <!-- 字符集 -->
        <property name="charset">utf8mb4</property>
        <!-- 处理线程数 -->
        <property name="processors">4</property>
        <!-- 后端连接超时时间 -->
        <property name="idleTimeout">300000</property>
    </system>
    
    <!-- 用户配置 -->
    <user name="root" defaultAccount="true">
        <!-- 密码 -->
        <property name="password">123456</property>
        <!-- 可访问的逻辑库 -->
        <property name="schemas">testdb</property>
        <!-- 是否只读 -->
        <property name="readOnly">false</property>
    </user>
    
    <!-- 只读用户 -->
    <user name="readonly">
        <property name="password">123456</property>
        <property name="schemas">testdb</property>
        <property name="readOnly">true</property>
    </user>
    
</mycat:server>
```

#### 6.3.2 schema.xml - 数据库配置

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
    
    <!-- 逻辑库配置 -->
    <schema name="testdb" checkSQLschema="true" sqlMaxLimit="100" dataNode="dn1">
        <!-- 
            不配置 table 标签时，所有表都使用默认的 dataNode
            如果需要分表，在这里配置 table 标签
        -->
    </schema>
    
    <!-- 数据节点配置 -->
    <dataNode name="dn1" dataHost="host1" database="testdb" />
    
    <!-- 数据主机配置（读写分离核心配置） -->
    <dataHost name="host1" 
              maxCon="1000" 
              minCon="10" 
              balance="1"
              writeType="0" 
              dbType="mysql" 
              dbDriver="jdbc"
              switchType="1" 
              slaveThreshold="100">
        
        <!-- 心跳检测 SQL -->
        <heartbeat>select user()</heartbeat>
        
        <!-- 主库（写库） -->
        <writeHost host="master" 
                   url="jdbc:mysql://192.168.1.100:3306?useSSL=false&amp;serverTimezone=Asia/Shanghai" 
                   user="root" 
                   password="root123">
            
            <!-- 从库（读库）配置在 writeHost 内部 -->
            <readHost host="slave1" 
                      url="jdbc:mysql://192.168.1.101:3306?useSSL=false&amp;serverTimezone=Asia/Shanghai" 
                      user="root" 
                      password="root123" />
            
            <readHost host="slave2" 
                      url="jdbc:mysql://192.168.1.102:3306?useSSL=false&amp;serverTimezone=Asia/Shanghai" 
                      user="root" 
                      password="root123" />
        </writeHost>
        
        <!-- 备用主库（主库故障时切换） -->
        <writeHost host="master_backup" 
                   url="jdbc:mysql://192.168.1.103:3306?useSSL=false&amp;serverTimezone=Asia/Shanghai" 
                   user="root" 
                   password="root123" />
    </dataHost>
    
</mycat:schema>
```

**关键参数说明**：

| 参数 | 说明 |
|------|------|
| balance="0" | 不开启读写分离，所有读操作发送到 writeHost |
| balance="1" | 全部 readHost 和 stand by writeHost 参与读操作 |
| balance="2" | 所有读操作随机分发到 writeHost 和 readHost |
| balance="3" | 所有读操作随机分发到 readHost |
| writeType="0" | 所有写操作发送到第一个 writeHost |
| writeType="1" | 所有写操作随机发送到 writeHost |
| switchType="1" | 自动切换（心跳检测失败后切换） |
| switchType="-1" | 不自动切换 |
| slaveThreshold | 从库延迟阈值（秒），超过则不参与读操作 |

### 6.4 启动 MyCat

```bash
# 启动
./bin/mycat start

# 停止
./bin/mycat stop

# 重启
./bin/mycat restart

# 查看状态
./bin/mycat status

# 查看日志
tail -f logs/mycat.log
```

### 6.5 应用连接 MyCat

应用程序只需要把数据库连接地址改为 MyCat 的地址即可，无需修改任何代码。

```yaml
# application.yml
spring:
  datasource:
    # 连接 MyCat，而不是直接连接 MySQL
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://192.168.1.200:8066/testdb?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
    username: root
    password: 123456
    hikari:
      pool-name: MyCatPool
      minimum-idle: 5
      maximum-pool-size: 20
```

### 6.6 MyCat 管理

```bash
# 连接 MyCat 管理端口
mysql -h 192.168.1.200 -P 9066 -u root -p

# 查看帮助
show @@help;

# 查看数据源状态
show @@datasource;

# 查看心跳状态
show @@heartbeat;

# 查看连接状态
show @@connection;

# 查看后端连接
show @@backend;

# 重新加载配置
reload @@config;

# 切换数据源
switch @@datasource name;
```

---

## 7. 数据一致性问题

### 7.1 主从延迟问题

**问题描述**：主库写入数据后，从库可能还没有同步完成，此时从从库读取会读不到最新数据。

```
时间线：
T1: 主库写入数据 A
T2: 应用从从库读取数据 A  ← 可能读不到！
T3: 从库同步完成
T4: 应用从从库读取数据 A  ← 可以读到

主从延迟时间 = T3 - T1
```

### 7.2 解决方案

#### 7.2.1 方案一：强制走主库

```java
/**
 * 写后读场景，强制走主库
 */
@Service
public class OrderService {
    
    @Transactional
    public Order createOrder(Order order) {
        // 1. 创建订单（主库）
        orderMapper.insert(order);
        
        // 2. 查询订单详情（强制主库）
        // 方案 A：使用事务，ShardingSphere 自动走主库
        // 方案 B：使用 HintManager
        try (HintManager hintManager = HintManager.getInstance()) {
            hintManager.setWriteRouteOnly();
            return orderMapper.selectById(order.getId());
        }
    }
}
```

#### 7.2.2 方案二：延迟读取

```java
/**
 * 延迟读取，等待主从同步
 */
@Service
public class OrderService {
    
    public Order createAndGetOrder(Order order) {
        // 1. 创建订单
        orderMapper.insert(order);
        
        // 2. 等待主从同步（简单粗暴，不推荐）
        try {
            Thread.sleep(100); // 等待 100ms
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
        
        // 3. 从从库读取
        return orderMapper.selectById(order.getId());
    }
}
```

#### 7.2.3 方案三：缓存方案

```java
/**
 * 使用缓存解决主从延迟
 */
@Service
public class OrderService {
    
    @Autowired
    private RedisTemplate<String, Order> redisTemplate;
    
    private static final String ORDER_CACHE_KEY = "order:";
    private static final long CACHE_EXPIRE_SECONDS = 60;
    
    public Order createOrder(Order order) {
        // 1. 写入数据库
        orderMapper.insert(order);
        
        // 2. 写入缓存
        String cacheKey = ORDER_CACHE_KEY + order.getId();
        redisTemplate.opsForValue().set(cacheKey, order, CACHE_EXPIRE_SECONDS, TimeUnit.SECONDS);
        
        return order;
    }
    
    public Order getOrder(Long id) {
        String cacheKey = ORDER_CACHE_KEY + id;
        
        // 1. 先查缓存
        Order order = redisTemplate.opsForValue().get(cacheKey);
        if (order != null) {
            return order;
        }
        
        // 2. 缓存没有，查数据库（从库）
        order = orderMapper.selectById(id);
        
        // 3. 写入缓存
        if (order != null) {
            redisTemplate.opsForValue().set(cacheKey, order, CACHE_EXPIRE_SECONDS, TimeUnit.SECONDS);
        }
        
        return order;
    }
}
```

#### 7.2.4 方案四：半同步复制

```sql
-- 在主库开启半同步复制
-- 确保至少一个从库收到数据后才返回

-- 安装半同步复制插件
INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';

-- 主库配置
SET GLOBAL rpl_semi_sync_master_enabled = 1;
SET GLOBAL rpl_semi_sync_master_timeout = 1000; -- 超时时间 1 秒

-- 从库配置
SET GLOBAL rpl_semi_sync_slave_enabled = 1;

-- 重启从库 IO 线程
STOP SLAVE IO_THREAD;
START SLAVE IO_THREAD;

-- 查看半同步状态
SHOW STATUS LIKE 'Rpl_semi_sync%';
```

#### 7.2.5 方案五：业务层面规避

```java
/**
 * 业务层面规避主从延迟
 * 
 * 思路：写操作返回完整数据，避免写后立即读
 */
@RestController
@RequestMapping("/api/orders")
public class OrderController {
    
    @PostMapping
    public Order createOrder(@RequestBody OrderRequest request) {
        // 创建订单后直接返回订单对象
        // 而不是返回 ID 让前端再查询
        Order order = orderService.createOrder(request);
        
        // 返回完整的订单信息，前端无需再次查询
        return order;
    }
}
```

### 7.3 主从延迟监控

```sql
-- 查看从库延迟
SHOW SLAVE STATUS\G

-- 关键字段
-- Seconds_Behind_Master: 延迟秒数
-- Slave_IO_Running: Yes
-- Slave_SQL_Running: Yes

-- 如果 Seconds_Behind_Master 持续增大，说明从库跟不上主库
```

```java
/**
 * 主从延迟监控
 */
@Component
@Slf4j
public class ReplicationLagMonitor {
    
    @Autowired
    private JdbcTemplate slaveJdbcTemplate;
    
    @Scheduled(fixedRate = 5000) // 每 5 秒检查一次
    public void checkReplicationLag() {
        try {
            Map<String, Object> status = slaveJdbcTemplate.queryForMap("SHOW SLAVE STATUS");
            
            Object secondsBehindMaster = status.get("Seconds_Behind_Master");
            String slaveIORunning = (String) status.get("Slave_IO_Running");
            String slaveSQLRunning = (String) status.get("Slave_SQL_Running");
            
            if (!"Yes".equals(slaveIORunning) || !"Yes".equals(slaveSQLRunning)) {
                log.error("主从复制异常！IO_Running: {}, SQL_Running: {}", 
                         slaveIORunning, slaveSQLRunning);
                // 发送告警
            }
            
            if (secondsBehindMaster != null) {
                long lag = ((Number) secondsBehindMaster).longValue();
                if (lag > 10) {
                    log.warn("主从延迟过高: {} 秒", lag);
                    // 发送告警
                }
            }
        } catch (Exception e) {
            log.error("检查主从延迟失败", e);
        }
    }
}
```


---

## 8. 常见错误与排查

### 8.1 数据源切换不生效

#### 错误现象

```
所有查询都走主库，从库没有流量
```

#### 原因分析

```java
// 原因 1：切面顺序问题
// @Transactional 的切面先于数据源切换切面执行
// 事务开启时已经获取了主库连接

// 错误示例
@Service
public class UserService {
    
    @Transactional  // 事务切面先执行，获取主库连接
    @ReadOnly       // 数据源切面后执行，但连接已经获取
    public User getUser(Long id) {
        return userMapper.selectById(id);
    }
}
```

#### 解决方案

```java
// 方案 1：确保数据源切面优先级高于事务切面
@Aspect
@Component
@Order(-1)  // 数字越小，优先级越高
public class DataSourceAspect {
    // ...
}

// 方案 2：只读方法不加事务
@Service
public class UserService {
    
    // 查询方法不需要事务
    @ReadOnly
    public User getUser(Long id) {
        return userMapper.selectById(id);
    }
    
    // 写方法才加事务
    @Transactional
    public void updateUser(User user) {
        userMapper.update(user);
    }
}

// 方案 3：使用 ShardingSphere，自动处理
```

### 8.2 ThreadLocal 内存泄漏

#### 错误现象

```
长时间运行后，内存持续增长
或者数据源切换混乱
```

#### 原因分析

```java
// ThreadLocal 没有及时清理
public class DataSourceContextHolder {
    private static final ThreadLocal<DataSourceType> CONTEXT_HOLDER = new ThreadLocal<>();
    
    public static void setDataSourceType(DataSourceType type) {
        CONTEXT_HOLDER.set(type);
    }
    
    // 忘记调用 remove()
}
```

#### 解决方案

```java
// 方案 1：在切面的 finally 中清理
@Around("servicePointcut()")
public Object around(ProceedingJoinPoint point) throws Throwable {
    try {
        DataSourceContextHolder.setDataSourceType(DataSourceType.SLAVE);
        return point.proceed();
    } finally {
        // 必须清理！
        DataSourceContextHolder.clearDataSourceType();
    }
}

// 方案 2：使用 Filter 在请求结束后清理
@Component
public class DataSourceCleanFilter implements Filter {
    
    @Override
    public void doFilter(ServletRequest request, ServletResponse response, 
                        FilterChain chain) throws IOException, ServletException {
        try {
            chain.doFilter(request, response);
        } finally {
            DataSourceContextHolder.clearDataSourceType();
        }
    }
}

// 方案 3：使用 InheritableThreadLocal（子线程继承父线程的值）
// 注意：线程池场景下仍需手动清理
private static final ThreadLocal<DataSourceType> CONTEXT_HOLDER = 
    new InheritableThreadLocal<>();
```

### 8.3 主从数据不一致

#### 错误现象

```
从库查询的数据与主库不一致
或者从库查不到刚写入的数据
```

#### 排查步骤

```sql
-- 1. 检查主从复制状态
SHOW SLAVE STATUS\G

-- 关注以下字段：
-- Slave_IO_Running: Yes
-- Slave_SQL_Running: Yes
-- Seconds_Behind_Master: 0
-- Last_Error: (应该为空)

-- 2. 如果 Slave_SQL_Running 为 No，查看错误
-- Last_SQL_Error 会显示具体错误

-- 3. 常见错误处理

-- 错误 1：主键冲突
-- Error 'Duplicate entry 'xxx' for key 'PRIMARY''
-- 解决：跳过错误或手动修复数据
STOP SLAVE;
SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1;
START SLAVE;

-- 错误 2：表不存在
-- Error 'Table 'xxx' doesn't exist'
-- 解决：在从库创建缺失的表

-- 错误 3：GTID 不一致
-- 解决：重新同步从库
STOP SLAVE;
RESET SLAVE ALL;
CHANGE MASTER TO ...;
START SLAVE;
```

### 8.4 连接池耗尽

#### 错误现象

```
HikariPool-1 - Connection is not available, request timed out after 30000ms.
```

#### 原因分析

```java
// 原因 1：连接泄漏（连接没有正确关闭）
public void badExample() {
    Connection conn = dataSource.getConnection();
    // 执行 SQL...
    // 忘记关闭连接！
}

// 原因 2：连接池配置过小
// 原因 3：慢查询占用连接时间过长
// 原因 4：死锁导致连接无法释放
```

#### 解决方案

```yaml
# 1. 调整连接池配置
spring:
  datasource:
    hikari:
      # 最大连接数
      maximum-pool-size: 20
      # 最小空闲连接
      minimum-idle: 5
      # 连接超时时间
      connection-timeout: 30000
      # 空闲连接超时时间
      idle-timeout: 600000
      # 连接最大生命周期
      max-lifetime: 1800000
      # 连接泄漏检测阈值（毫秒）
      leak-detection-threshold: 60000
```

```java
// 2. 确保连接正确关闭
// 使用 try-with-resources
public void goodExample() {
    try (Connection conn = dataSource.getConnection();
         PreparedStatement ps = conn.prepareStatement(sql);
         ResultSet rs = ps.executeQuery()) {
        // 处理结果
    } catch (SQLException e) {
        // 处理异常
    }
    // 自动关闭连接
}

// 3. 使用 Spring 的 JdbcTemplate（自动管理连接）
@Autowired
private JdbcTemplate jdbcTemplate;

public List<User> getUsers() {
    return jdbcTemplate.query("SELECT * FROM users", new BeanPropertyRowMapper<>(User.class));
}
```

### 8.5 事务中读写分离失效

#### 错误现象

```
在 @Transactional 方法中，所有操作都走主库
```

#### 原因分析

```java
// 这是正确的行为！
// 事务需要保证 ACID，必须在同一个数据库连接上执行
// 如果读写分离，可能导致：
// 1. 读到未提交的数据（脏读）
// 2. 事务回滚后，从库数据不一致
```

#### 解决方案

```java
// 方案 1：接受这个行为（推荐）
// 事务中的读操作走主库是正确的

// 方案 2：拆分事务
@Service
public class OrderService {
    
    // 查询方法不加事务，走从库
    public Order getOrder(Long id) {
        return orderMapper.selectById(id);
    }
    
    // 写方法加事务，走主库
    @Transactional
    public void updateOrder(Order order) {
        orderMapper.update(order);
    }
    
    // 组合方法
    public void processOrder(Long id) {
        // 1. 查询（从库）
        Order order = getOrder(id);
        
        // 2. 业务处理
        order.setStatus("PROCESSED");
        
        // 3. 更新（主库，事务）
        updateOrder(order);
    }
}

// 方案 3：使用只读事务
@Transactional(readOnly = true)  // 只读事务可以走从库
public List<Order> getOrders() {
    return orderMapper.selectAll();
}
```

### 8.6 错误速查表

| 错误现象 | 可能原因 | 解决方案 |
|---------|---------|---------|
| 所有查询走主库 | 切面顺序问题 | 设置 @Order(-1) |
| 数据源切换混乱 | ThreadLocal 未清理 | finally 中调用 remove() |
| 从库查不到数据 | 主从延迟 | 强制走主库或使用缓存 |
| 连接池耗尽 | 连接泄漏/配置过小 | 检查连接关闭/调整配置 |
| 事务中走从库 | 配置错误 | 事务中应该走主库 |
| 主从复制中断 | 网络/配置问题 | 检查 SHOW SLAVE STATUS |
| 数据不一致 | 复制错误 | 跳过错误或重新同步 |


